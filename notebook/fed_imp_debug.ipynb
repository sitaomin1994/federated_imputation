{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\\OneDrive\\Projects\\federated_imputation\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.data_preprocessing import load_data\n",
    "from src.modules.data_spliting import split_train_test\n",
    "from src.modules.data_partition import data_partition\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.modules.iterative_imputation.distributed_imputer import DistributedFeatureImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and set up clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 10\n",
    "seed = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 5) (30, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': '5',\n",
       " 'important_features_idx': [2, 3, 0, 1],\n",
       " 'features_idx': [0, 1, 2, 3, 4],\n",
       " 'num_cols': 4,\n",
       " 'task_type': 'classification',\n",
       " 'clf_type': 'multi-class',\n",
       " 'data_type': 'tabular'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, config = load_data('iris')\n",
    "data_list = split_train_test(data, seed = 21)\n",
    "train_data, test_data = data_list[0]\n",
    "print(train_data.shape, test_data.shape)\n",
    "n_cols = train_data.shape[1] - 1\n",
    "config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num partitions: 10 size of data: (120, 5)\n"
     ]
    }
   ],
   "source": [
    "data_partitions = data_partition(\n",
    "    strategy='full', params = {}, data=train_data.values, n_clients=n_clients, seed=seed\n",
    ")\n",
    "print(\"num partitions: {} size of data: {}\".format(len(data_partitions), data_partitions[0].shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Missing Values to Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fed_imp.sub_modules.missing_simulate.ms_simulate.mar_simulate import (\n",
    "    simulate_nan_mary_quantile, simulate_nan_mar_quantile, simulate_nan_mar_sigmoid)\n",
    "from src.fed_imp.sub_modules.missing_simulate.ms_simulate.mcar_simulate import simulate_nan_mcar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 12 12 12  0]\n",
      "[36 36 36 36  0]\n",
      "[60 60 60 60  0]\n",
      "[84 84 84 84  0]\n",
      "[108 108 108 108   0]\n",
      "[12 12 12 12  0]\n",
      "[36 36 36 36  0]\n",
      "[60 60 60 60  0]\n",
      "[84 84 84 84  0]\n",
      "[108 108 108 108   0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_groups1 = [0, 1, 2, 3, 4]\n",
    "client_groups2 = [5, 6, 7, 8, 9]\n",
    "cols = [0, 1, 2, 3]\n",
    "missing_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "train_data_ms_list = []\n",
    "for idx, client in enumerate(client_groups1):\n",
    "    seed = seed + 100\n",
    "    train_data = data_partitions[client]\n",
    "    X_train_ms = simulate_nan_mcar(train_data[:, :-1], cols = cols, missing_ratio=missing_ratios[idx], seed = seed)\n",
    "    train_data_ms = np.concatenate((X_train_ms, train_data[:, -1].reshape(-1,1)), axis=1)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "for idx, client in enumerate(client_groups2):\n",
    "    seed = seed + 200\n",
    "    train_data = data_partitions[client]\n",
    "    X_train_ms = simulate_nan_mcar(train_data[:, :-1], cols = cols, missing_ratio=missing_ratios[idx], seed = seed)\n",
    "    train_data_ms = np.concatenate((X_train_ms, train_data[:, -1].reshape(-1,1)), axis=1)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    msno.matrix(pd.DataFrame(train_data_ms_list[i]), ax=ax[i//5, i%5], sparkline=False, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42489712 0.43595679 0.46531701 0.45987654]\n",
      " [0.38955026 0.4375     0.468523   0.45882937]\n",
      " [0.39212963 0.43055556 0.48446328 0.4875    ]\n",
      " [0.41512346 0.4212963  0.42278719 0.50694444]\n",
      " [0.52083333 0.35069444 0.49435028 0.56597222]\n",
      " [0.41743827 0.43325617 0.43895166 0.47415123]\n",
      " [0.41005291 0.44890873 0.48930589 0.47519841]\n",
      " [0.42777778 0.43055556 0.47429379 0.44375   ]\n",
      " [0.4367284  0.43634259 0.47269303 0.41435185]\n",
      " [0.44675926 0.5        0.37429379 0.31944444]]\n",
      "[0.42812904 0.43250661 0.45849789 0.46060185]\n"
     ]
    }
   ],
   "source": [
    "class Client:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_train_ms):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_train_ms = X_train_ms\n",
    "        self.mask = np.isnan(X_train_ms)\n",
    "        self.X_train_filled = X_train_ms\n",
    "        self.X_train_pt = None\n",
    "        self.imputer = None\n",
    "\n",
    "# client data\n",
    "clients = []\n",
    "for i in range(10):\n",
    "    X_train, y_train = data_partitions[i][:, :-1], data_partitions[i][:, -1]\n",
    "    X_train_ms = train_data_ms_list[i][:, :-1]\n",
    "    clients.append(Client(X_train, y_train, X_train_ms))\n",
    "\n",
    "imputer_list = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    client_obj.imp = DistributedFeatureImputer(client_obj.mask, estimator_num=None, estimator_cat='logistic_cv')\n",
    "\n",
    "# initial imputation\n",
    "global_mean = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    global_mean.append(np.nanmean(client_obj.X_train_ms, axis = 0))\n",
    "global_mean = np.array(global_mean)\n",
    "print(global_mean)\n",
    "\n",
    "# avgerage initial imputation\n",
    "mean_avg = np.nanmean(global_mean, axis = 0)\n",
    "print(mean_avg)\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    for col in range(client_obj.X_train_ms.shape[1]):\n",
    "        client_obj.X_train_filled[:, col] = np.where(client_obj.mask[:, col], mean_avg[col], client_obj.X_train_ms[:, col])\n",
    "        client_obj.X_train_pt = client_obj.X_train_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280185</td>\n",
       "      <td>0.195410</td>\n",
       "      <td>0.351188</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.214330</td>\n",
       "      <td>-0.068819</td>\n",
       "      <td>-0.398590</td>\n",
       "      <td>-0.163013</td>\n",
       "      <td>0.076227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.280185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875135</td>\n",
       "      <td>0.843008</td>\n",
       "      <td>0.049292</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.739904</td>\n",
       "      <td>-0.630868</td>\n",
       "      <td>-0.297995</td>\n",
       "      <td>0.153613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195410</td>\n",
       "      <td>0.875135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.556797</td>\n",
       "      <td>0.355148</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.914856</td>\n",
       "      <td>-0.210569</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351188</td>\n",
       "      <td>0.843008</td>\n",
       "      <td>0.556797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.438582</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.448897</td>\n",
       "      <td>-0.890357</td>\n",
       "      <td>-0.751026</td>\n",
       "      <td>-0.358452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.049292</td>\n",
       "      <td>0.355148</td>\n",
       "      <td>-0.438582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772318</td>\n",
       "      <td>0.393741</td>\n",
       "      <td>0.619789</td>\n",
       "      <td>0.866729</td>\n",
       "      <td>0.987612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.214330</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.772318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859724</td>\n",
       "      <td>0.352052</td>\n",
       "      <td>0.489713</td>\n",
       "      <td>0.783667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.068819</td>\n",
       "      <td>0.739904</td>\n",
       "      <td>0.914856</td>\n",
       "      <td>0.448897</td>\n",
       "      <td>0.393741</td>\n",
       "      <td>0.859724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019821</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>0.427364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.398590</td>\n",
       "      <td>-0.630868</td>\n",
       "      <td>-0.210569</td>\n",
       "      <td>-0.890357</td>\n",
       "      <td>0.619789</td>\n",
       "      <td>0.352052</td>\n",
       "      <td>-0.019821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753061</td>\n",
       "      <td>0.534357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.163013</td>\n",
       "      <td>-0.297995</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>-0.751026</td>\n",
       "      <td>0.866729</td>\n",
       "      <td>0.489713</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>0.753061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.076227</td>\n",
       "      <td>0.153613</td>\n",
       "      <td>0.446009</td>\n",
       "      <td>-0.358452</td>\n",
       "      <td>0.987612</td>\n",
       "      <td>0.783667</td>\n",
       "      <td>0.427364</td>\n",
       "      <td>0.534357</td>\n",
       "      <td>0.853184</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.280185  0.195410  0.351188  0.006298 -0.214330 -0.068819   \n",
       "1  0.280185  1.000000  0.875135  0.843008  0.049292  0.484973  0.739904   \n",
       "2  0.195410  0.875135  1.000000  0.556797  0.355148  0.758186  0.914856   \n",
       "3  0.351188  0.843008  0.556797  1.000000 -0.438582  0.013460  0.448897   \n",
       "4  0.006298  0.049292  0.355148 -0.438582  1.000000  0.772318  0.393741   \n",
       "5 -0.214330  0.484973  0.758186  0.013460  0.772318  1.000000  0.859724   \n",
       "6 -0.068819  0.739904  0.914856  0.448897  0.393741  0.859724  1.000000   \n",
       "7 -0.398590 -0.630868 -0.210569 -0.890357  0.619789  0.352052 -0.019821   \n",
       "8 -0.163013 -0.297995  0.003736 -0.751026  0.866729  0.489713 -0.004942   \n",
       "9  0.076227  0.153613  0.446009 -0.358452  0.987612  0.783667  0.427364   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.398590 -0.163013  0.076227  \n",
       "1 -0.630868 -0.297995  0.153613  \n",
       "2 -0.210569  0.003736  0.446009  \n",
       "3 -0.890357 -0.751026 -0.358452  \n",
       "4  0.619789  0.866729  0.987612  \n",
       "5  0.352052  0.489713  0.783667  \n",
       "6 -0.019821 -0.004942  0.427364  \n",
       "7  1.000000  0.753061  0.534357  \n",
       "8  0.753061  1.000000  0.853184  \n",
       "9  0.534357  0.853184  1.000000  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "col_idx = 0\n",
    "coefs = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    oh = OneHotEncoder(drop = 'first')\n",
    "    target_onehot = oh.fit_transform(client_obj.y_train.reshape(-1, 1)).toarray()\n",
    "    mask = np.arange(client_obj.X_train_filled.shape[1]) != col_idx\n",
    "    X = np.concatenate([client_obj.X_train_filled[:, mask], target_onehot], axis = 1)\n",
    "    y = client_obj.mask[:, col_idx]\n",
    "    coef = []\n",
    "    lr = LogisticRegressionCV(Cs = [1e-2], penalty = 'l2', cv=StratifiedKFold(5), random_state=0, max_iter=1000, n_jobs=-1, class_weight='balanced')\n",
    "    #lr = LogisticRegression(C = 1e-2, penalty = 'l2', random_state=seed, max_iter=1000, n_jobs=-1)\n",
    "    lr.fit(X, y)\n",
    "    coef = np.concatenate([lr.coef_[0], lr.intercept_])\n",
    "    coefs.append(coef)\n",
    "\n",
    "coef_df = pd.DataFrame([coef for coef in coefs]).T\n",
    "print(coef_df.T.apply(lambda row: np.linalg.norm(row, ord = 2)/len(row), axis = 1))\n",
    "coef_df.corr(method = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.184249e-03</td>\n",
       "      <td>-0.015422</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.001499</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>-0.008993</td>\n",
       "      <td>-0.006720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.166422e-03</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>-0.006412</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>-0.006452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.016468e-02</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>-0.006631</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.015546</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>0.006983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.099383e-07</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>-0.026903</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>-0.050990</td>\n",
       "      <td>-0.025353</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>-0.028293</td>\n",
       "      <td>-0.033454</td>\n",
       "      <td>-0.050998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.424048e-04</td>\n",
       "      <td>0.054578</td>\n",
       "      <td>0.045494</td>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>-0.009873</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>0.024406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.484503e-03</td>\n",
       "      <td>-0.038785</td>\n",
       "      <td>-0.031095</td>\n",
       "      <td>-0.012529</td>\n",
       "      <td>0.019899</td>\n",
       "      <td>-0.003070</td>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.016464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0 -1.184249e-03 -0.015422  0.005404 -0.001499 -0.002739  0.003580  0.008529   \n",
       "1 -8.166422e-03  0.026443  0.028309  0.004987 -0.012065  0.006042  0.008399   \n",
       "2  2.016468e-02  0.024402  0.019447  0.007485  0.001209 -0.006631 -0.001143   \n",
       "3 -4.099383e-07  0.001600 -0.026903  0.011462 -0.050990 -0.025353 -0.010439   \n",
       "4 -3.424048e-04  0.054578  0.045494  0.011417  0.024456  0.025243  0.021850   \n",
       "5 -5.484503e-03 -0.038785 -0.031095 -0.012529  0.019899 -0.003070 -0.011617   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.014541 -0.008993 -0.006720  \n",
       "1 -0.006412 -0.003594 -0.006452  \n",
       "2 -0.015546 -0.003949  0.006983  \n",
       "3 -0.028293 -0.033454 -0.050998  \n",
       "4 -0.009873 -0.001086  0.024406  \n",
       "5  0.016472  0.019710  0.016464  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.003745\n",
       "1    0.012929\n",
       "2    0.011749\n",
       "3    0.003734\n",
       "4    0.010204\n",
       "5    0.006197\n",
       "6    0.004904\n",
       "7    0.006798\n",
       "8    0.006704\n",
       "9    0.010004\n",
       "dtype: float64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.T.apply(lambda row: np.linalg.norm(row, ord = 2)/len(row), axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAR_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n",
      "[60 60 60  0  0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_groups1 = [0, 1, 2, 3, 4]\n",
    "client_groups2 = [5, 6, 7, 8, 9]\n",
    "cols = [0, 1, 2]\n",
    "missing_ratio1 = [0.5 for i in range(5)]\n",
    "missing_ratio2 = [0.5 for i in range(5)]\n",
    "train_data_ms_list = []\n",
    "for idx, client in enumerate(client_groups1):\n",
    "    seed = seed + 100\n",
    "    train_data = data_partitions[client]\n",
    "    X_train_ms = simulate_nan_mar_quantile(\n",
    "        train_data[:, :-1], cols = cols, missing_ratio=missing_ratio1[idx], missing_func = 'left', obs=True, seed = seed)\n",
    "    train_data_ms = np.concatenate((X_train_ms, train_data[:, -1].reshape(-1,1)), axis=1)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "for idx, client in enumerate(client_groups2):\n",
    "    seed = seed + 200\n",
    "    train_data = data_partitions[client]\n",
    "    X_train_ms = simulate_nan_mar_quantile(\n",
    "        train_data[:, :-1], cols = cols, missing_ratio=missing_ratio2[idx], missing_func = 'right', obs=True, seed = seed)\n",
    "    train_data_ms = np.concatenate((X_train_ms, train_data[:, -1].reshape(-1,1)), axis=1)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    msno.matrix(pd.DataFrame(train_data_ms_list[i]), ax=ax[i//5, i%5], sparkline=False, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58287037 0.39236111 0.70536723 0.45763889]\n",
      " [0.58287037 0.39305556 0.70451977 0.45763889]\n",
      " [0.58703704 0.38958333 0.70677966 0.45763889]\n",
      " [0.5787037  0.39027778 0.70451977 0.45763889]\n",
      " [0.58055556 0.39166667 0.70536723 0.45763889]\n",
      " [0.25509259 0.47916667 0.22146893 0.45763889]\n",
      " [0.25509259 0.48055556 0.22118644 0.45763889]\n",
      " [0.26342593 0.47986111 0.22118644 0.45763889]\n",
      " [0.2625     0.48125    0.22118644 0.45763889]\n",
      " [0.26203704 0.48125    0.22090395 0.45763889]]\n",
      "[0.42101852 0.43590278 0.46324859 0.45763889]\n"
     ]
    }
   ],
   "source": [
    "class Client:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_train_ms):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_train_ms = X_train_ms\n",
    "        self.mask = np.isnan(X_train_ms)\n",
    "        self.X_train_filled = X_train_ms\n",
    "        self.X_train_pt = None\n",
    "        self.imputer = None\n",
    "\n",
    "# client data\n",
    "clients = []\n",
    "for i in range(10):\n",
    "    X_train, y_train = data_partitions[i][:, :-1], data_partitions[i][:, -1]\n",
    "    X_train_ms = train_data_ms_list[i][:, :-1]\n",
    "    clients.append(Client(X_train, y_train, X_train_ms))\n",
    "\n",
    "imputer_list = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    client_obj.imp = DistributedFeatureImputer(client_obj.mask, estimator_num=None, estimator_cat='logistic_cv')\n",
    "\n",
    "# initial imputation\n",
    "global_mean = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    global_mean.append(np.nanmean(client_obj.X_train_ms, axis = 0))\n",
    "global_mean = np.array(global_mean)\n",
    "print(global_mean)\n",
    "\n",
    "# avgerage initial imputation\n",
    "mean_avg = np.nanmean(global_mean, axis = 0)\n",
    "print(mean_avg)\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    for col in range(client_obj.X_train_ms.shape[1]):\n",
    "        client_obj.X_train_filled[:, col] = np.where(client_obj.mask[:, col], mean_avg[col], client_obj.X_train_ms[:, col])\n",
    "        client_obj.X_train_pt = client_obj.X_train_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.049272\n",
      "1    0.049396\n",
      "2    0.049459\n",
      "3    0.049187\n",
      "4    0.049295\n",
      "5    0.047941\n",
      "6    0.047948\n",
      "7    0.047835\n",
      "8    0.047955\n",
      "9    0.047949\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.998830</td>\n",
       "      <td>-0.998854</td>\n",
       "      <td>-0.998838</td>\n",
       "      <td>-0.998865</td>\n",
       "      <td>-0.998865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>-0.998761</td>\n",
       "      <td>-0.998788</td>\n",
       "      <td>-0.998746</td>\n",
       "      <td>-0.998802</td>\n",
       "      <td>-0.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>-0.998734</td>\n",
       "      <td>-0.998760</td>\n",
       "      <td>-0.998706</td>\n",
       "      <td>-0.998773</td>\n",
       "      <td>-0.998771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>-0.998904</td>\n",
       "      <td>-0.998920</td>\n",
       "      <td>-0.998918</td>\n",
       "      <td>-0.998927</td>\n",
       "      <td>-0.998927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.998832</td>\n",
       "      <td>-0.998855</td>\n",
       "      <td>-0.998833</td>\n",
       "      <td>-0.998866</td>\n",
       "      <td>-0.998865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.998830</td>\n",
       "      <td>-0.998761</td>\n",
       "      <td>-0.998734</td>\n",
       "      <td>-0.998904</td>\n",
       "      <td>-0.998832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.998854</td>\n",
       "      <td>-0.998788</td>\n",
       "      <td>-0.998760</td>\n",
       "      <td>-0.998920</td>\n",
       "      <td>-0.998855</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.998838</td>\n",
       "      <td>-0.998746</td>\n",
       "      <td>-0.998706</td>\n",
       "      <td>-0.998918</td>\n",
       "      <td>-0.998833</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.998865</td>\n",
       "      <td>-0.998802</td>\n",
       "      <td>-0.998773</td>\n",
       "      <td>-0.998927</td>\n",
       "      <td>-0.998866</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.998865</td>\n",
       "      <td>-0.998800</td>\n",
       "      <td>-0.998771</td>\n",
       "      <td>-0.998927</td>\n",
       "      <td>-0.998865</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.999988  0.999976  0.999984  0.999999 -0.998830 -0.998854   \n",
       "1  0.999988  1.000000  0.999997  0.999950  0.999990 -0.998761 -0.998788   \n",
       "2  0.999976  0.999997  1.000000  0.999937  0.999981 -0.998734 -0.998760   \n",
       "3  0.999984  0.999950  0.999937  1.000000  0.999985 -0.998904 -0.998920   \n",
       "4  0.999999  0.999990  0.999981  0.999985  1.000000 -0.998832 -0.998855   \n",
       "5 -0.998830 -0.998761 -0.998734 -0.998904 -0.998832  1.000000  0.999999   \n",
       "6 -0.998854 -0.998788 -0.998760 -0.998920 -0.998855  0.999999  1.000000   \n",
       "7 -0.998838 -0.998746 -0.998706 -0.998918 -0.998833  0.999983  0.999984   \n",
       "8 -0.998865 -0.998802 -0.998773 -0.998927 -0.998866  0.999997  1.000000   \n",
       "9 -0.998865 -0.998800 -0.998771 -0.998927 -0.998865  0.999997  1.000000   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.998838 -0.998865 -0.998865  \n",
       "1 -0.998746 -0.998802 -0.998800  \n",
       "2 -0.998706 -0.998773 -0.998771  \n",
       "3 -0.998918 -0.998927 -0.998927  \n",
       "4 -0.998833 -0.998866 -0.998865  \n",
       "5  0.999983  0.999997  0.999997  \n",
       "6  0.999984  1.000000  1.000000  \n",
       "7  1.000000  0.999983  0.999984  \n",
       "8  0.999983  1.000000  1.000000  \n",
       "9  0.999984  1.000000  1.000000  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "col_idx = 0\n",
    "coefs = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    oh = OneHotEncoder(drop = 'first')\n",
    "    target_onehot = oh.fit_transform(client_obj.y_train.reshape(-1, 1)).toarray()\n",
    "    mask = np.arange(client_obj.X_train_filled.shape[1]) != col_idx\n",
    "    X = np.concatenate([client_obj.X_train_filled[:, mask], target_onehot], axis = 1)\n",
    "    y = client_obj.mask[:, col_idx]\n",
    "    coef = []\n",
    "    lr = LogisticRegressionCV(Cs = [1e-2], penalty = 'l2', cv=StratifiedKFold(5), random_state=0, max_iter=1000, n_jobs=-1, class_weight='balanced')\n",
    "    #lr = LogisticRegression(C = 1e-2, penalty = 'l2', random_state=seed, max_iter=1000, n_jobs=-1)\n",
    "    lr.fit(X, y)\n",
    "    coef = np.concatenate([lr.coef_[0], lr.intercept_])\n",
    "    coefs.append(coef)\n",
    "\n",
    "coef_df = pd.DataFrame([coef for coef in coefs]).T\n",
    "print(coef_df.T.apply(lambda row: np.linalg.norm(row, ord = 2)/len(row), axis = 1))\n",
    "coef_df.corr(method = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAR sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55 54 60  0  0]\n",
      "[56 69 61  0  0]\n",
      "[66 62 54  0  0]\n",
      "[57 71 61  0  0]\n",
      "[59 55 54  0  0]\n",
      "[59 54 58  0  0]\n",
      "[54 61 65  0  0]\n",
      "[62 59 54  0  0]\n",
      "[61 54 61  0  0]\n",
      "[61 62 59  0  0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_groups1 = [0, 1, 2, 3, 4]\n",
    "client_groups2 = [5, 6, 7, 8, 9]\n",
    "cols = [0, 1, 2]\n",
    "missing_ratio = 0.5\n",
    "train_data_ms_list = []\n",
    "for client in client_groups1:\n",
    "    seed = seed + 100\n",
    "    train_data = data_partitions[client]\n",
    "    X_train_ms = simulate_nan_mar_sigmoid(\n",
    "        train_data[:, :-1], cols = cols, missing_ratio=missing_ratio, missing_func = 'left', obs=True, k = 'all', \n",
    "        seed = seed)\n",
    "    train_data_ms = np.concatenate((X_train_ms, train_data[:, -1].reshape(-1,1)), axis=1)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "for client in client_groups2:\n",
    "    seed = seed + 200\n",
    "    train_data = data_partitions[client]\n",
    "    X_train_ms = simulate_nan_mar_sigmoid(\n",
    "        train_data[:, :-1], cols = cols, missing_ratio=missing_ratio, missing_func = 'right', obs=True, k = 'all', \n",
    "        seed = seed)\n",
    "    train_data_ms = np.concatenate((X_train_ms, train_data[:, -1].reshape(-1,1)), axis=1)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    msno.matrix(pd.DataFrame(train_data_ms_list[i]), ax=ax[i//5, i%5], sparkline=False, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50512821 0.40467172 0.57627119 0.45763889]\n",
      " [0.49305556 0.37254902 0.61706406 0.45763889]\n",
      " [0.50205761 0.40445402 0.55675398 0.45763889]\n",
      " [0.5207231  0.40646259 0.5794312  0.45763889]\n",
      " [0.50227687 0.40576923 0.58320493 0.45763889]\n",
      " [0.34107468 0.45454545 0.33078185 0.45763889]\n",
      " [0.34385522 0.46539548 0.31679507 0.45763889]\n",
      " [0.32806513 0.45013661 0.34745763 0.45763889]\n",
      " [0.35357815 0.45707071 0.32461936 0.45763889]\n",
      " [0.35310734 0.45617816 0.34009447 0.45763889]]\n",
      "[0.42429219 0.4277233  0.45724737 0.45763889]\n",
      "0    0.024291\n",
      "1    0.028035\n",
      "2    0.026186\n",
      "3    0.034547\n",
      "4    0.029878\n",
      "5    0.026762\n",
      "6    0.025819\n",
      "7    0.028383\n",
      "8    0.026288\n",
      "9    0.025700\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990409</td>\n",
       "      <td>0.967492</td>\n",
       "      <td>0.978861</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>-0.957285</td>\n",
       "      <td>-0.985547</td>\n",
       "      <td>-0.989276</td>\n",
       "      <td>-0.944066</td>\n",
       "      <td>-0.979976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990378</td>\n",
       "      <td>0.996724</td>\n",
       "      <td>0.948694</td>\n",
       "      <td>-0.985987</td>\n",
       "      <td>-0.993711</td>\n",
       "      <td>-0.993930</td>\n",
       "      <td>-0.971980</td>\n",
       "      <td>-0.962704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.967492</td>\n",
       "      <td>0.990378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>0.978916</td>\n",
       "      <td>-0.997966</td>\n",
       "      <td>-0.989202</td>\n",
       "      <td>-0.984907</td>\n",
       "      <td>-0.993266</td>\n",
       "      <td>-0.935547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978861</td>\n",
       "      <td>0.996724</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969185</td>\n",
       "      <td>-0.995271</td>\n",
       "      <td>-0.995089</td>\n",
       "      <td>-0.992630</td>\n",
       "      <td>-0.986998</td>\n",
       "      <td>-0.952952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.948694</td>\n",
       "      <td>0.978916</td>\n",
       "      <td>0.969185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.986279</td>\n",
       "      <td>-0.948471</td>\n",
       "      <td>-0.939540</td>\n",
       "      <td>-0.983540</td>\n",
       "      <td>-0.862022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.957285</td>\n",
       "      <td>-0.985987</td>\n",
       "      <td>-0.997966</td>\n",
       "      <td>-0.995271</td>\n",
       "      <td>-0.986279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983395</td>\n",
       "      <td>0.980731</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.925253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.985547</td>\n",
       "      <td>-0.993711</td>\n",
       "      <td>-0.989202</td>\n",
       "      <td>-0.995089</td>\n",
       "      <td>-0.948471</td>\n",
       "      <td>0.983395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997508</td>\n",
       "      <td>0.980081</td>\n",
       "      <td>0.975538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.989276</td>\n",
       "      <td>-0.993930</td>\n",
       "      <td>-0.984907</td>\n",
       "      <td>-0.992630</td>\n",
       "      <td>-0.939540</td>\n",
       "      <td>0.980731</td>\n",
       "      <td>0.997508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974433</td>\n",
       "      <td>0.981158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.944066</td>\n",
       "      <td>-0.971980</td>\n",
       "      <td>-0.993266</td>\n",
       "      <td>-0.986998</td>\n",
       "      <td>-0.983540</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.980081</td>\n",
       "      <td>0.974433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.979976</td>\n",
       "      <td>-0.962704</td>\n",
       "      <td>-0.935547</td>\n",
       "      <td>-0.952952</td>\n",
       "      <td>-0.862022</td>\n",
       "      <td>0.925253</td>\n",
       "      <td>0.975538</td>\n",
       "      <td>0.981158</td>\n",
       "      <td>0.921403</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.990409  0.967492  0.978861  0.898810 -0.957285 -0.985547   \n",
       "1  0.990409  1.000000  0.990378  0.996724  0.948694 -0.985987 -0.993711   \n",
       "2  0.967492  0.990378  1.000000  0.997585  0.978916 -0.997966 -0.989202   \n",
       "3  0.978861  0.996724  0.997585  1.000000  0.969185 -0.995271 -0.995089   \n",
       "4  0.898810  0.948694  0.978916  0.969185  1.000000 -0.986279 -0.948471   \n",
       "5 -0.957285 -0.985987 -0.997966 -0.995271 -0.986279  1.000000  0.983395   \n",
       "6 -0.985547 -0.993711 -0.989202 -0.995089 -0.948471  0.983395  1.000000   \n",
       "7 -0.989276 -0.993930 -0.984907 -0.992630 -0.939540  0.980731  0.997508   \n",
       "8 -0.944066 -0.971980 -0.993266 -0.986998 -0.983540  0.993708  0.980081   \n",
       "9 -0.979976 -0.962704 -0.935547 -0.952952 -0.862022  0.925253  0.975538   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.989276 -0.944066 -0.979976  \n",
       "1 -0.993930 -0.971980 -0.962704  \n",
       "2 -0.984907 -0.993266 -0.935547  \n",
       "3 -0.992630 -0.986998 -0.952952  \n",
       "4 -0.939540 -0.983540 -0.862022  \n",
       "5  0.980731  0.993708  0.925253  \n",
       "6  0.997508  0.980081  0.975538  \n",
       "7  1.000000  0.974433  0.981158  \n",
       "8  0.974433  1.000000  0.921403  \n",
       "9  0.981158  0.921403  1.000000  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Client:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_train_ms):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_train_ms = X_train_ms\n",
    "        self.mask = np.isnan(X_train_ms)\n",
    "        self.X_train_filled = X_train_ms\n",
    "        self.X_train_pt = None\n",
    "        self.imputer = None\n",
    "\n",
    "# client data\n",
    "clients = []\n",
    "for i in range(10):\n",
    "    X_train, y_train = data_partitions[i][:, :-1], data_partitions[i][:, -1]\n",
    "    X_train_ms = train_data_ms_list[i][:, :-1]\n",
    "    clients.append(Client(X_train, y_train, X_train_ms))\n",
    "\n",
    "imputer_list = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    client_obj.imp = DistributedFeatureImputer(client_obj.mask, estimator_num=None, estimator_cat='logistic_cv')\n",
    "\n",
    "# initial imputation\n",
    "global_mean = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    global_mean.append(np.nanmean(client_obj.X_train_ms, axis = 0))\n",
    "global_mean = np.array(global_mean)\n",
    "print(global_mean)\n",
    "\n",
    "# avgerage initial imputation\n",
    "mean_avg = np.nanmean(global_mean, axis = 0)\n",
    "print(mean_avg)\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    for col in range(client_obj.X_train_ms.shape[1]):\n",
    "        client_obj.X_train_filled[:, col] = np.where(client_obj.mask[:, col], mean_avg[col], client_obj.X_train_ms[:, col])\n",
    "        client_obj.X_train_pt = client_obj.X_train_filled.copy()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "col_idx = 0\n",
    "coefs = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    oh = OneHotEncoder(drop = 'first')\n",
    "    target_onehot = oh.fit_transform(client_obj.y_train.reshape(-1, 1)).toarray()\n",
    "    mask = np.arange(client_obj.X_train_filled.shape[1]) != col_idx\n",
    "    X = np.concatenate([client_obj.X_train_filled[:, mask], target_onehot], axis = 1)\n",
    "    y = client_obj.mask[:, col_idx]\n",
    "    coef = []\n",
    "    lr = LogisticRegressionCV(Cs = [1e-2], penalty = 'l2', cv=StratifiedKFold(5), random_state=0, max_iter=1000, n_jobs=-1, class_weight='balanced')\n",
    "    #lr = LogisticRegression(C = 1e-2, penalty = 'l2', random_state=seed, max_iter=1000, n_jobs=-1)\n",
    "    lr.fit(X, y)\n",
    "    coef = np.concatenate([lr.coef_[0], lr.intercept_])\n",
    "    coefs.append(coef)\n",
    "\n",
    "coef_df = pd.DataFrame([coef for coef in coefs]).T\n",
    "print(coef_df.T.apply(lambda row: np.linalg.norm(row, ord = 2)/len(row), axis = 1))\n",
    "coef_df.corr(method = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 12 12 12  0]\n",
      "[36 36 36 36  0]\n",
      "[60 60 60 60  0]\n",
      "[84 84 84 84  0]\n",
      "[108 108 108 108   0]\n",
      "[12 12 12 12  0]\n",
      "[36 36 36 36  0]\n",
      "[60 60 60 60  0]\n",
      "[84 84 84 84  0]\n",
      "[108 108 108 108   0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_groups1 = [0, 1, 2, 3, 4]\n",
    "client_groups2 = [5, 6, 7, 8, 9]\n",
    "cols = [0, 1, 2, 3]\n",
    "missing_ratio1 = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "missing_ratio2 = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "train_data_ms_list = []\n",
    "for idx, client in enumerate(client_groups1):\n",
    "    seed = seed + 100\n",
    "    train_data = data_partitions[client]\n",
    "    train_data_ms = simulate_nan_mary_quantile(\n",
    "        train_data, cols = cols, missing_ratio=missing_ratio1[idx], missing_func='left', strict=True, seed = seed)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "for idx, client in enumerate(client_groups2):\n",
    "    seed = seed + 200\n",
    "    train_data = data_partitions[client]\n",
    "    train_data_ms = simulate_nan_mary_quantile(\n",
    "        train_data, cols = cols, missing_ratio=missing_ratio2[idx], missing_func='right', strict=True, seed = seed)\n",
    "    print(np.isnan(train_data_ms).sum(axis = 0))\n",
    "    train_data_ms_list.append(train_data_ms)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    msno.matrix(pd.DataFrame(train_data_ms_list[i]), ax=ax[i//5, i%5], sparkline=False, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44547325 0.42013889 0.50502197 0.5007716 ]\n",
      " [0.51917989 0.36706349 0.62853107 0.63095238]\n",
      " [0.56574074 0.37222222 0.68587571 0.69930556]\n",
      " [0.60802469 0.38310185 0.74717514 0.7974537 ]\n",
      " [0.55092593 0.40625    0.74576271 0.79513889]\n",
      " [0.39531893 0.44097222 0.43298807 0.41782407]\n",
      " [0.34193122 0.45138889 0.33918483 0.31299603]\n",
      " [0.28842593 0.5        0.23728814 0.21388889]\n",
      " [0.19753086 0.58796296 0.07862524 0.05671296]\n",
      " [0.23148148 0.57986111 0.08757062 0.03819444]]\n",
      "[0.41440329 0.45089616 0.44880235 0.44632385]\n",
      "0    0.039629\n",
      "1    0.041573\n",
      "2    0.040721\n",
      "3    0.060658\n",
      "4    0.043873\n",
      "5    0.053178\n",
      "6    0.054933\n",
      "7    0.039119\n",
      "8    0.042495\n",
      "9    0.028108\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935951</td>\n",
       "      <td>0.789595</td>\n",
       "      <td>0.567557</td>\n",
       "      <td>0.434197</td>\n",
       "      <td>-0.614867</td>\n",
       "      <td>-0.471656</td>\n",
       "      <td>-0.813968</td>\n",
       "      <td>-0.979742</td>\n",
       "      <td>-0.869137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835866</td>\n",
       "      <td>0.581468</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>-0.614464</td>\n",
       "      <td>-0.508958</td>\n",
       "      <td>-0.819515</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.952773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789595</td>\n",
       "      <td>0.835866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928545</td>\n",
       "      <td>0.885023</td>\n",
       "      <td>-0.931017</td>\n",
       "      <td>-0.895325</td>\n",
       "      <td>-0.983472</td>\n",
       "      <td>-0.814936</td>\n",
       "      <td>-0.751547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567557</td>\n",
       "      <td>0.581468</td>\n",
       "      <td>0.928545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976886</td>\n",
       "      <td>-0.990793</td>\n",
       "      <td>-0.985011</td>\n",
       "      <td>-0.913335</td>\n",
       "      <td>-0.561723</td>\n",
       "      <td>-0.470007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.434197</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>0.885023</td>\n",
       "      <td>0.976886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.947364</td>\n",
       "      <td>-0.993466</td>\n",
       "      <td>-0.863262</td>\n",
       "      <td>-0.459226</td>\n",
       "      <td>-0.429052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.614867</td>\n",
       "      <td>-0.614464</td>\n",
       "      <td>-0.931017</td>\n",
       "      <td>-0.990793</td>\n",
       "      <td>-0.947364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>0.905973</td>\n",
       "      <td>0.594709</td>\n",
       "      <td>0.476924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.471656</td>\n",
       "      <td>-0.508958</td>\n",
       "      <td>-0.895325</td>\n",
       "      <td>-0.985011</td>\n",
       "      <td>-0.993466</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887122</td>\n",
       "      <td>0.485704</td>\n",
       "      <td>0.434617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.813968</td>\n",
       "      <td>-0.819515</td>\n",
       "      <td>-0.983472</td>\n",
       "      <td>-0.913335</td>\n",
       "      <td>-0.863262</td>\n",
       "      <td>0.905973</td>\n",
       "      <td>0.887122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827512</td>\n",
       "      <td>0.765615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.979742</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.814936</td>\n",
       "      <td>-0.561723</td>\n",
       "      <td>-0.459226</td>\n",
       "      <td>0.594709</td>\n",
       "      <td>0.485704</td>\n",
       "      <td>0.827512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.869137</td>\n",
       "      <td>-0.952773</td>\n",
       "      <td>-0.751547</td>\n",
       "      <td>-0.470007</td>\n",
       "      <td>-0.429052</td>\n",
       "      <td>0.476924</td>\n",
       "      <td>0.434617</td>\n",
       "      <td>0.765615</td>\n",
       "      <td>0.942781</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.935951  0.789595  0.567557  0.434197 -0.614867 -0.471656   \n",
       "1  0.935951  1.000000  0.835866  0.581468  0.502922 -0.614464 -0.508958   \n",
       "2  0.789595  0.835866  1.000000  0.928545  0.885023 -0.931017 -0.895325   \n",
       "3  0.567557  0.581468  0.928545  1.000000  0.976886 -0.990793 -0.985011   \n",
       "4  0.434197  0.502922  0.885023  0.976886  1.000000 -0.947364 -0.993466   \n",
       "5 -0.614867 -0.614464 -0.931017 -0.990793 -0.947364  1.000000  0.954459   \n",
       "6 -0.471656 -0.508958 -0.895325 -0.985011 -0.993466  0.954459  1.000000   \n",
       "7 -0.813968 -0.819515 -0.983472 -0.913335 -0.863262  0.905973  0.887122   \n",
       "8 -0.979742 -0.981000 -0.814936 -0.561723 -0.459226  0.594709  0.485704   \n",
       "9 -0.869137 -0.952773 -0.751547 -0.470007 -0.429052  0.476924  0.434617   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.813968 -0.979742 -0.869137  \n",
       "1 -0.819515 -0.981000 -0.952773  \n",
       "2 -0.983472 -0.814936 -0.751547  \n",
       "3 -0.913335 -0.561723 -0.470007  \n",
       "4 -0.863262 -0.459226 -0.429052  \n",
       "5  0.905973  0.594709  0.476924  \n",
       "6  0.887122  0.485704  0.434617  \n",
       "7  1.000000  0.827512  0.765615  \n",
       "8  0.827512  1.000000  0.942781  \n",
       "9  0.765615  0.942781  1.000000  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Client:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_train_ms):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_train_ms = X_train_ms\n",
    "        self.mask = np.isnan(X_train_ms)\n",
    "        self.X_train_filled = X_train_ms\n",
    "        self.X_train_pt = None\n",
    "        self.imputer = None\n",
    "\n",
    "# client data\n",
    "clients = []\n",
    "for i in range(10):\n",
    "    X_train, y_train = data_partitions[i][:, :-1], data_partitions[i][:, -1]\n",
    "    X_train_ms = train_data_ms_list[i][:, :-1]\n",
    "    clients.append(Client(X_train, y_train, X_train_ms))\n",
    "\n",
    "imputer_list = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    client_obj.imp = DistributedFeatureImputer(client_obj.mask, estimator_num=None, estimator_cat='logistic_cv')\n",
    "\n",
    "# initial imputation\n",
    "global_mean = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    global_mean.append(np.nanmean(client_obj.X_train_ms, axis = 0))\n",
    "global_mean = np.array(global_mean)\n",
    "print(global_mean)\n",
    "\n",
    "# avgerage initial imputation\n",
    "mean_avg = np.nanmean(global_mean, axis = 0)\n",
    "print(mean_avg)\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    for col in range(client_obj.X_train_ms.shape[1]):\n",
    "        client_obj.X_train_filled[:, col] = np.where(client_obj.mask[:, col], mean_avg[col], client_obj.X_train_ms[:, col])\n",
    "        client_obj.X_train_pt = client_obj.X_train_filled.copy()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "col_idx = 0\n",
    "coefs = []\n",
    "for client in range(n_clients):\n",
    "    client_obj = clients[client]\n",
    "    oh = OneHotEncoder(drop = 'first')\n",
    "    target_onehot = oh.fit_transform(client_obj.y_train.reshape(-1, 1)).toarray()\n",
    "    mask = np.arange(client_obj.X_train_filled.shape[1]) != col_idx\n",
    "    X = np.concatenate([client_obj.X_train_filled[:, mask], target_onehot], axis = 1)\n",
    "    y = client_obj.mask[:, col_idx]\n",
    "    coef = []\n",
    "    lr = LogisticRegressionCV(Cs = [1e-2], penalty = 'l2', cv=StratifiedKFold(5), random_state=0, max_iter=1000, n_jobs=-1, class_weight='balanced')\n",
    "    #lr = LogisticRegression(C = 1e-2, penalty = 'l2', random_state=seed, max_iter=1000, n_jobs=-1)\n",
    "    lr.fit(X, y)\n",
    "    coef = np.concatenate([lr.coef_[0], lr.intercept_])\n",
    "    coefs.append(coef)\n",
    "\n",
    "coef_df = pd.DataFrame([coef for coef in coefs]).T\n",
    "print(coef_df.T.apply(lambda row: np.linalg.norm(row, ord = 2)/len(row), axis = 1))\n",
    "coef_df.corr(method = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077660</td>\n",
       "      <td>0.135407</td>\n",
       "      <td>0.247220</td>\n",
       "      <td>0.300218</td>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.716937</td>\n",
       "      <td>0.898949</td>\n",
       "      <td>0.960508</td>\n",
       "      <td>0.872747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064107</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.244715</td>\n",
       "      <td>0.768732</td>\n",
       "      <td>0.751694</td>\n",
       "      <td>0.910937</td>\n",
       "      <td>0.989541</td>\n",
       "      <td>0.985047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135407</td>\n",
       "      <td>0.064107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056377</td>\n",
       "      <td>0.070070</td>\n",
       "      <td>0.934148</td>\n",
       "      <td>0.930521</td>\n",
       "      <td>0.984338</td>\n",
       "      <td>0.928319</td>\n",
       "      <td>0.913441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247220</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.056377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.998284</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>0.944510</td>\n",
       "      <td>0.777951</td>\n",
       "      <td>0.739808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300218</td>\n",
       "      <td>0.244715</td>\n",
       "      <td>0.070070</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.995678</td>\n",
       "      <td>0.924298</td>\n",
       "      <td>0.743815</td>\n",
       "      <td>0.731151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.768732</td>\n",
       "      <td>0.934148</td>\n",
       "      <td>0.998284</td>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.062623</td>\n",
       "      <td>0.229976</td>\n",
       "      <td>0.279348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.716937</td>\n",
       "      <td>0.751694</td>\n",
       "      <td>0.930521</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>0.995678</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065649</td>\n",
       "      <td>0.248264</td>\n",
       "      <td>0.273921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.898949</td>\n",
       "      <td>0.910937</td>\n",
       "      <td>0.984338</td>\n",
       "      <td>0.944510</td>\n",
       "      <td>0.924298</td>\n",
       "      <td>0.062623</td>\n",
       "      <td>0.065649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>0.114176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.960508</td>\n",
       "      <td>0.989541</td>\n",
       "      <td>0.928319</td>\n",
       "      <td>0.777951</td>\n",
       "      <td>0.743815</td>\n",
       "      <td>0.229976</td>\n",
       "      <td>0.248264</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.872747</td>\n",
       "      <td>0.985047</td>\n",
       "      <td>0.913441</td>\n",
       "      <td>0.739808</td>\n",
       "      <td>0.731151</td>\n",
       "      <td>0.279348</td>\n",
       "      <td>0.273921</td>\n",
       "      <td>0.114176</td>\n",
       "      <td>0.029620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.077660  0.135407  0.247220  0.300218  0.758082  0.716937   \n",
       "1  0.077660  0.000000  0.064107  0.221303  0.244715  0.768732  0.751694   \n",
       "2  0.135407  0.064107  0.000000  0.056377  0.070070  0.934148  0.930521   \n",
       "3  0.247220  0.221303  0.056377  0.000000  0.007639  0.998284  0.995631   \n",
       "4  0.300218  0.244715  0.070070  0.007639  0.000000  0.986295  0.995678   \n",
       "5  0.758082  0.768732  0.934148  0.998284  0.986295  0.000000  0.009982   \n",
       "6  0.716937  0.751694  0.930521  0.995631  0.995678  0.009982  0.000000   \n",
       "7  0.898949  0.910937  0.984338  0.944510  0.924298  0.062623  0.065649   \n",
       "8  0.960508  0.989541  0.928319  0.777951  0.743815  0.229976  0.248264   \n",
       "9  0.872747  0.985047  0.913441  0.739808  0.731151  0.279348  0.273921   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.898949  0.960508  0.872747  \n",
       "1  0.910937  0.989541  0.985047  \n",
       "2  0.984338  0.928319  0.913441  \n",
       "3  0.944510  0.777951  0.739808  \n",
       "4  0.924298  0.743815  0.731151  \n",
       "5  0.062623  0.229976  0.279348  \n",
       "6  0.065649  0.248264  0.273921  \n",
       "7  0.000000  0.073871  0.114176  \n",
       "8  0.073871  0.000000  0.029620  \n",
       "9  0.114176  0.029620  0.000000  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = coef_df.corr(method = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))\n",
    "w = 1 - (a + 1)/2\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 3, 3, 1, 1, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "a = coef_df.corr(method = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))\n",
    "w = 1 - (a + 1)/2\n",
    "agg = AgglomerativeClustering(\n",
    "\t\tn_clusters=None, metric='cosine', linkage='average', distance_threshold=0.2\n",
    "\t)\n",
    "\n",
    "agg.fit_predict(coef_df.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithm 1\n",
    "    - weighted average based on dissimilarity between missing mechaisms\n",
    "        - alpha\\*mech_dissimilarity + (1-alpha)\\*(1- missing_rate)\n",
    "- Algorithm 2\n",
    "    - cluster based on missing mechanism distance\n",
    "    - within cluster -> weighted average based on missing rate\n",
    "    - find distance between clusters based on missing mechanism distance\n",
    "     \n",
    "    - For each client:\n",
    "        - find the its cluster\n",
    "        - weighted average based on distance between clsuters\n",
    "\n",
    "- Algorithm 3\n",
    "    - For every client:\n",
    "        - cluster based on missing mechanism distance\n",
    "        - within cluster -> weighted average based on missing rate\n",
    "        - between clusters -> weighted average based on missing mechanism distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 3 3 1 1 1 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00763884, 0.00998235, 0.0296195 , 0.06322381, 0.06413624,\n",
       "       0.07765958, 0.20216173, 0.20325916, 0.88565456])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(agg.fit_predict(w))\n",
    "agg.distances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.077660\n",
       "2    0.135407\n",
       "3    0.247220\n",
       "4    0.300218\n",
       "5    0.758082\n",
       "6    0.716937\n",
       "7    0.898949\n",
       "8    0.960508\n",
       "9    0.872747\n",
       "dtype: float64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_client = coef_df[0].values\n",
    "coefs_centroid = coef_df.T.values\n",
    "coef_df = pd.DataFrame([coef for coef in coefs_centroid]).T\n",
    "coef_client = pd.Series(coef_client)\n",
    "weight = coef_df.corrwith(coef_client, method=lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))\n",
    "weight = 1 - (weight + 1)/2\n",
    "weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
